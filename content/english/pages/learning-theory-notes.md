---
title: "Notes on Learning Theory"
meta_title: "Notes on Learning Theory"
description: "Graduate-level study notes on statistical learning theory based on Francis Bach's Learning Theory from First Principles"
draft: false
---

These notes were made while studying Francis Bach's *[Learning Theory from First Principles](https://www.di.ens.fr/~fbach/)*, with the guidance of [Prof. Michael Riis Andersen](https://michaelriis.github.io/). The material is graduate-level, covering the mathematical foundations of why and how machine learning algorithms generalize.

The notes follow Bach's text chapter by chapter. Each chapter includes preliminary definitions, worked derivations, standalone proofs, and a brief discussion of the significance of the results. I also drew on a range of outside sources to supplement proofs and build intuition.

Topics covered include concentration inequalities (Hoeffding, McDiarmid), PAC learning, empirical risk minimization, Rademacher complexity, and optimization for machine learning.

<p style="text-align: center;"><a href="/Notes_on_Learning_Theory.pdf" style="font-weight: bold;">View PDF</a></p>

<iframe src="/Notes_on_Learning_Theory.pdf" width="100%" height="900px" style="border: none; margin-top: 1rem;"></iframe>
